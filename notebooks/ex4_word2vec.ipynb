{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Similarity using Word Embeddings\n",
    "\n",
    "In this notebook we're going to play around with pre build word embeddings and do some fun calcultations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from keras.utils import get_file\n",
    "import gensim\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.pylabtools import figsize\n",
    "figsize(10, 10)\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import json\n",
    "from collections import Counter\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by downloading a pretrained model from Google News. We're using `zcat` to unzip the file, so you need to make sure you have that installed or replace it by something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'GoogleNews-vectors-negative300.bin'\n",
    "path = get_file(MODEL + '.gz', 'https://s3.amazonaws.com/dl4j-distribution/%s.gz' % MODEL)\n",
    "if not os.path.isdir('generated'):\n",
    "    os.mkdir('generated')\n",
    "\n",
    "unzipped = os.path.join('generated', MODEL)\n",
    "if not os.path.isfile(unzipped):\n",
    "    with open(unzipped, 'wb') as fout:\n",
    "        zcat = subprocess.Popen(['zcat'],\n",
    "                          stdin=open(path),\n",
    "                          stdout=fout\n",
    "                         )\n",
    "        zcat.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format(unzipped, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take this model for a spin by looking at what things are most similar to espresso. As expected, coffee like items show up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(positive=['espresso'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the famous equation, what is like woman if king is like man? We create a quick method to these calculations here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_is_to_B_as_C_is_to(a, b, c, topn=1):\n",
    "    a, b, c = map(lambda x:x if type(x) == list else [x], (a, b, c))\n",
    "    res = model.most_similar(positive=b + c, negative=a, topn=topn)\n",
    "    if len(res):\n",
    "        if topn == 1:\n",
    "            return res[0][0]\n",
    "        return [x[0] for x in res]\n",
    "    return None\n",
    "\n",
    "A_is_to_B_as_C_is_to('man', 'woman', 'king')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this equation to acurately predict the capitals of countries by looking at what has the same relationship as Berlin has to Germany for selected countries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country in 'Italy', 'France', 'India', 'China':\n",
    "    print('%s is the capital of %s' % \n",
    "          (A_is_to_B_as_C_is_to('Germany', 'Berlin', country), country))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can do the same for important products for given companies. Here we seed the products equation with two products, the iPhone for Apple and Starbucks_coffee for Starbucks. Note that numbers are replaced by # in the embedding model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for company in 'Google', 'IBM', 'Boeing', 'Microsoft', 'Samsung':\n",
    "    products = A_is_to_B_as_C_is_to(\n",
    "        ['Starbucks', 'Apple'], \n",
    "        ['Starbucks_coffee', 'iPhone'], \n",
    "        company, topn=3)\n",
    "    print('%s -> %s' % \n",
    "          (company, ', '.join(products)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some clustering by picking three categories of items, drinks, countries and sports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beverages = ['espresso', 'beer', 'vodka', 'wine', 'cola', 'tea']\n",
    "countries = ['Italy', 'Germany', 'Russia', 'France', 'USA', 'India']\n",
    "sports = ['soccer', 'handball', 'hockey', 'cycling', 'basketball', 'cricket']\n",
    "\n",
    "items = beverages + countries + sports\n",
    "len(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And looking up their vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_vectors = [(item, model[item]) \n",
    "                    for item in items\n",
    "                    if item in model]\n",
    "len(item_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use TSNE for clustering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = np.asarray([x[1] for x in item_vectors])\n",
    "lengths = np.linalg.norm(vectors, axis=1)\n",
    "norm_vectors = (vectors.T / lengths).T\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=10, verbose=2).fit_transform(norm_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And matplotlib to show the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tsne[:,0]\n",
    "y=tsne[:,1]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y)\n",
    "\n",
    "for item, x1, y1 in zip(item_vectors, x, y):\n",
    "    ax.annotate(item[0], (x1, y1), size=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
